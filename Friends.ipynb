{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech to text functions\n",
    "These functions are different attempts in translating Sophia's audio files into text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First attempt: simple `speech_recognition` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready!\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "audio_file = sr.AudioFile('KZ-and-Amy.wav')\n",
    "with audio_file as source: \n",
    "    r.adjust_for_ambient_noise(source) \n",
    "    audio = r.listen(source,timeout=10)\n",
    "result = r.recognize_google(audio)\n",
    "with open('KZ-and-Amy.txt',mode ='w') as file: \n",
    "    file.write(\"Recognized text:\") \n",
    "    file.write(\"\\n\") \n",
    "    file.write(result) \n",
    "    print(\"ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did not work... we need to try breaking the large file into smaller files so the function can translate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second function: splitting audio into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joey/Desktop/Luck/env/lib/python3.8/site-packages/pydub/utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# importing libraries \n",
    "import speech_recognition as sr \n",
    "\n",
    "import os \n",
    "\n",
    "from pydub import AudioSegment \n",
    "from pydub.silence import split_on_silence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that splits the audio file into chunks \n",
    "# and applies speech recognition \n",
    "def silence_based_conversion(path): \n",
    "\n",
    "    # open the audio file stored in \n",
    "    # the local system as a wav file. \n",
    "    song = AudioSegment.from_wav(path) \n",
    "\n",
    "    # open a file where we will concatenate \n",
    "    # and store the recognized text \n",
    "    fh = open(\"recognized.txt\", \"w+\") \n",
    "        \n",
    "    # split track where silence is 0.5 seconds \n",
    "    # or more and get chunks \n",
    "    chunks = split_on_silence(song, \n",
    "        # must be silent for at least 0.5 seconds \n",
    "        # or 500 ms. adjust this value based on user \n",
    "        # requirement. if the speaker stays silent for \n",
    "        # longer, increase this value. else, decrease it. \n",
    "        min_silence_len = 500, \n",
    "\n",
    "        # consider it silent if quieter than -16 dBFS \n",
    "        # adjust this per requirement \n",
    "        silence_thresh = -16\n",
    "    ) \n",
    "\n",
    "    # create a directory to store the audio chunks. \n",
    "    try: \n",
    "        os.mkdir('audio_chunks') \n",
    "    except(FileExistsError): \n",
    "        pass\n",
    "\n",
    "    # move into the directory to \n",
    "    # store the audio files. \n",
    "    os.chdir('audio_chunks') \n",
    "\n",
    "    i = 0\n",
    "    # process each chunk \n",
    "    for chunk in chunks: \n",
    "            \n",
    "        # Create 0.5 seconds silence chunk \n",
    "        chunk_silent = AudioSegment.silent(duration = 1000) \n",
    "\n",
    "        # add 0.5 sec silence to beginning and \n",
    "        # end of audio chunk. This is done so that \n",
    "        # it doesn't seem abruptly sliced. \n",
    "        audio_chunk = chunk_silent + chunk + chunk_silent \n",
    "\n",
    "        # export audio chunk and save it in \n",
    "        # the current directory. \n",
    "        print(\"saving chunk{0}.wav\".format(i)) \n",
    "        # specify the bitrate to be 192 k \n",
    "        audio_chunk.export(\"./chunk{0}.wav\".format(i), bitrate ='192k', format =\"wav\") \n",
    "\n",
    "        # the name of the newly created chunk \n",
    "        filename = 'chunk'+str(i)+'.wav'\n",
    "\n",
    "        print(\"Processing chunk \"+str(i)) \n",
    "\n",
    "        # get the name of the newly created chunk \n",
    "        # in the AUDIO_FILE variable for later use. \n",
    "        file = filename \n",
    "\n",
    "        # create a speech recognition object \n",
    "        r = sr.Recognizer() \n",
    "\n",
    "        # recognize the chunk \n",
    "        with sr.AudioFile(file) as source: \n",
    "            # remove this if it is not working \n",
    "            # correctly. \n",
    "            r.adjust_for_ambient_noise(source) \n",
    "            audio_listened = r.listen(source) \n",
    "\n",
    "        try: \n",
    "            # try converting it to text \n",
    "            rec = r.recognize_google(audio_listened) \n",
    "            # write the output to the file. \n",
    "            fh.write(rec+\". \") \n",
    "\n",
    "        # catch any errors. \n",
    "        except sr.UnknownValueError: \n",
    "            print(\"Could not understand audio\") \n",
    "\n",
    "        except sr.RequestError as e: \n",
    "            print(\"Could not request results. check your internet connection\") \n",
    "\n",
    "        i += 1\n",
    "\n",
    "    os.chdir('..') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the audio file path\n",
      "/Users/joey/Desktop/Luck/KZ-and-Amy.wav\n",
      "saving chunk0.wav\n",
      "Processing chunk 0\n",
      "Could not understand audio\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "        \n",
    "    print('Enter the audio file path') \n",
    "\n",
    "    path = input() \n",
    "\n",
    "    silence_based_conversion(path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function \"could not understand audio\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third function: breaking into chunks again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import speech_recognition as sr \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "# create a speech recognition object\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# a function that splits the audio file into chunks\n",
    "# and applies speech recognition\n",
    "def get_large_audio_transcription(path):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_wav(path)  \n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 1250,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-4,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=100,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)\n",
    "            # try converting it to text\n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                print(chunk_filename, \":\", text)\n",
    "                whole_text += text\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text\n",
    "\n",
    "get_large_audio_transcription('/Users/joey/Desktop/Luck/KZ-and-Amy.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-chunks/chunk1.wav : My first question. \n",
      "audio-chunks/chunk2.wav : But how do you say christ working through. \n",
      "Error: \n",
      "Error: \n",
      "Error: \n",
      "Error: \n",
      "audio-chunks/chunk7.wav : On it. \n",
      "audio-chunks/chunk8.wav : Butt lake mary lake sorority sucker like external club shows be like this person like has having connections like catholicism the path. \n",
      "Error: \n",
      "audio-chunks/chunk10.wav : But i like remember it happening so much. \n",
      "audio-chunks/chunk11.wav : So cool that. \n",
      "audio-chunks/chunk12.wav : Like happen like finds out things about them. \n",
      "audio-chunks/chunk13.wav : Another thing i think. \n",
      "Error: \n",
      "audio-chunks/chunk15.wav : I don't know to confide things and like exclusive friends and that's just like really awesome to see you like catherine doesn't have to like me and only on herself. \n",
      "audio-chunks/chunk16.wav : Yeah how do you. \n",
      "audio-chunks/chunk17.wav : I think one thing i've always admired about amy but i definitely. \n",
      "Error: \n",
      "Error: \n",
      "audio-chunks/chunk20.wav : Feel like amy is one. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"My first question. But how do you say christ working through. On it. Butt lake mary lake sorority sucker like external club shows be like this person like has having connections like catholicism the path. But i like remember it happening so much. So cool that. Like happen like finds out things about them. Another thing i think. I don't know to confide things and like exclusive friends and that's just like really awesome to see you like catherine doesn't have to like me and only on herself. Yeah how do you. I think one thing i've always admired about amy but i definitely. Feel like amy is one. \""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_large_audio_transcription('/Users/joey/Desktop/Luck/KZ-and-Amy.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has been the best attempt so far... not saying much, however\n",
    "\n",
    "Information on `split_on_silence` parameters:\n",
    "\n",
    "- min_silence_len - (in ms) minimum length of a silence to be used for\n",
    "    a split. default: 1000ms\n",
    "\n",
    "- silence_thresh - (in dBFS) anything quieter than this will be\n",
    "    considered silence. default: -16dBFS\n",
    "\n",
    "- keep_silence - (in ms) amount of silence to leave at the beginning\n",
    "    and end of the chunks. Keeps the sound from sounding like it is\n",
    "    abruptly cut off. (default: 100ms)\n",
    "\n",
    "After adjusting parameters for `split_on_silence`, here are the results:\n",
    "\n",
    "(1000,16,100) - default\n",
    "- 9 chunks, horrible translation\n",
    "\n",
    "(500,16,100)\n",
    "- 17 chunks, horrible translation\n",
    "\n",
    "(250,16,100)\n",
    "- 27 chunks, horrible translation\n",
    "\n",
    "(1000,8,100)\n",
    "- 15 chunks, okay translation\n",
    "\n",
    "(1000,12,100)\n",
    "- 10, okay translation\n",
    "\n",
    "(500,8,100)\n",
    "- 22 chunks, horrible translation\n",
    "\n",
    "(1500, 8,100)\n",
    "- 7 chunks, okay translation\n",
    "\n",
    "(1250,4,100)\n",
    "- 12 short chunks, bad translation\n",
    "\n",
    "### I have decided to try another function... this one cannot seem to be tuned. The translations are not accurate at all for this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking into chunks is a good idea... we just need a better source of translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another API - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
